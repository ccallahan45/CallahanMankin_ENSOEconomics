{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Panel data for ENSO and country-level economics\n",
    "#### Christopher Callahan\n",
    "#### Christopher.W.Callahan.GR@dartmouth.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mechanics\n",
    "Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "from rasterio import features\n",
    "from affine import Affine\n",
    "import geopandas as gp\n",
    "import descartes\n",
    "import cartopy as cart\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.feature import ShapelyFeature\n",
    "from scipy import signal, stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_gdp = \"../Data/WDI/\"\n",
    "loc_shp = \"../Data/ProcessedCountryShapefile/\"\n",
    "loc_regions = \"../Data/Regions/\"\n",
    "loc_pwt = \"../Data/PWT/\"\n",
    "loc_precip = \"../Data/CountryPrecip/\"\n",
    "loc_temp = \"../Data/CountryTemp/\"\n",
    "loc_enso = \"../Data/ENSO_Indices/\"\n",
    "loc_teleconnections = \"../Data/Teleconnections/\"\n",
    "loc_income_class = \"../Data/Income_Classes/\"\n",
    "loc_out = \"../Data/Panel/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp = gp.read_file(loc_shp)\n",
    "iso_shp = shp.ISO3.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_in = 1950\n",
    "y2_in = 2019\n",
    "y1 = 1960\n",
    "y2 = 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=FutureWarning,message=\"'base' in .resample()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read ENSO indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "enso_in = xr.open_dataset(loc_enso+\"obs_ENSO_indices_monthly_\"+str(y1)+\"-\"+str(y2)+\".nc\")\n",
    "E = enso_in.e_index\n",
    "C = enso_in.c_index\n",
    "nino3 = enso_in.nino3\n",
    "nino34 = enso_in.nino34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert ENSO indices to DJF annual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthly_to_yearly_mean(x):\n",
    "\n",
    "        # calculate annual mean from monthly data\n",
    "        # after weighting for the difference in month length\n",
    "        # x must be data-array with time coord\n",
    "        # xarray must be installed\n",
    "\n",
    "        # x_yr = x.resample(time=\"YS\").mean(dim=\"time\") is wrong\n",
    "        # because it doesn't weight for the # of days in each month\n",
    "\n",
    "        days_in_mon = x.time.dt.days_in_month\n",
    "        wgts = days_in_mon.groupby(\"time.year\")/days_in_mon.groupby(\"time.year\").sum()\n",
    "        ones = xr.where(x.isnull(),0.0,1.0)\n",
    "        x_sum = (x*wgts).resample(time=\"YS\").sum(dim=\"time\")\n",
    "        ones_out = (ones*wgts).resample(time=\"YS\").sum(dim=\"time\")\n",
    "        return(x_sum/ones_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "enso_time_ind = (E.time.dt.year>=y1)&(E.time.dt.year<=y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eshift = E[enso_time_ind].shift(time=1)\n",
    "Eshift.coords[\"time\"] = pd.date_range(start=str(y1)+\"-01-01\",end=str(y2)+\"-12-31\",freq=\"MS\")\n",
    "E_yr = monthly_to_yearly_mean(Eshift[Eshift.time.dt.month<=3])\n",
    "\n",
    "Cshift = C[enso_time_ind].shift(time=1)\n",
    "Cshift.coords[\"time\"] = pd.date_range(start=str(y1)+\"-01-01\",end=str(y2)+\"-12-31\",freq=\"MS\")\n",
    "C_yr = monthly_to_yearly_mean(Cshift[Cshift.time.dt.month<=3])\n",
    "\n",
    "nino3shift = nino3[enso_time_ind].shift(time=1)\n",
    "nino3shift.coords[\"time\"] = pd.date_range(start=str(y1)+\"-01-01\",end=str(y2)+\"-12-31\",freq=\"MS\")\n",
    "nino3_yr = monthly_to_yearly_mean(nino3shift[nino3shift.time.dt.month<=3])\n",
    "\n",
    "nino34shift = nino34[enso_time_ind].shift(time=1)\n",
    "nino34shift.coords[\"time\"] = pd.date_range(start=str(y1)+\"-01-01\",end=str(y2)+\"-12-31\",freq=\"MS\")\n",
    "nino34_yr = monthly_to_yearly_mean(nino34shift[nino34shift.time.dt.month<=3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in country temp and precip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_temp = 1900\n",
    "y2_temp = 2019\n",
    "# ObsEnsemble\n",
    "country_temp_monthly = xr.open_dataarray(loc_temp+\"BerkeleyEarth_country_temp_monthly_\"+str(y1_temp)+\"-\"+str(y2_temp)+\".nc\")\n",
    "country_temp_monthly_std = xr.open_dataarray(loc_temp+\"BerkeleyEarth_country_temp_monthly_std_\"+str(y1_temp)+\"-\"+str(y2_temp)+\".nc\")\n",
    "\n",
    "y1_precip = 1900\n",
    "y2_precip = 2019\n",
    "country_precip_monthly = xr.open_dataarray(loc_precip+\"GPCC_country_precip_monthly_\"+str(y1_precip)+\"-\"+str(y2_precip)+\".nc\")\n",
    "country_precip_monthly_std = xr.open_dataarray(loc_precip+\"GPCC_country_precip_monthly_std_\"+str(y1_precip)+\"-\"+str(y2_precip)+\".nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=FutureWarning,message=\"'base' in .resample\")\n",
    "\n",
    "country_temp = monthly_to_yearly_mean(country_temp_monthly.loc[:,str(y1)+\"-01-01\":str(y2)+\"-12-31\"])\n",
    "country_precip = monthly_to_yearly_mean(country_precip_monthly.loc[:,str(y1)+\"-01-01\":str(y2)+\"-12-31\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now read in GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdi_panel = pd.read_csv(loc_gdp+\"API_NY.GDP.PCAP.KD_DS2_en_csv_v2_3630804.csv\").drop(columns=[\"Country Name\",\"Indicator Name\",\"Indicator Code\"])\n",
    "wdi_panel_long1 = pd.melt(wdi_panel,id_vars=\"Country Code\",var_name=\"year\",value_name=\"gdppc\")\n",
    "wdi_panel_long1[\"year\"] = wdi_panel_long1.year.astype(int)\n",
    "wdi_panel_long = wdi_panel_long1.rename(columns={'Country Code':\"iso\"}).loc[(wdi_panel_long1.year>=y1)&(wdi_panel_long1.year<=y2),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpc_iso = np.unique(wdi_panel_long.iso.values)\n",
    "nc = len(gpc_iso)\n",
    "years = np.arange(y1,y2+1,1)\n",
    "years_repeat = np.tile(years,nc).flatten()\n",
    "iso_repeat = np.repeat(gpc_iso,len(years))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "panel = pd.DataFrame(np.transpose([years_repeat,iso_repeat]),columns=[\"year\",\"iso\"])\n",
    "panel[\"year\"] = panel[\"year\"].values.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add ENSO indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_yr_panel = xr.DataArray(E_yr.values,coords=[E_yr.time.dt.year.values],dims=[\"year\"])\n",
    "C_yr_panel = xr.DataArray(C_yr.values,coords=[E_yr.time.dt.year.values],dims=[\"year\"])\n",
    "E_yr_panel.name = \"e\"\n",
    "C_yr_panel.name = \"c\"\n",
    "E_yr_df = E_yr_panel.to_dataframe().reset_index()\n",
    "C_yr_df = C_yr_panel.to_dataframe().reset_index()\n",
    "nino3_yr_panel = xr.DataArray(nino3_yr.values,coords=[nino3_yr.time.dt.year.values],dims=[\"year\"])\n",
    "nino3_yr_panel.name = \"nino3\"\n",
    "nino3_yr_df = nino3_yr_panel.to_dataframe().reset_index()\n",
    "nino34_yr_panel = xr.DataArray(nino34_yr.values,coords=[nino34_yr.time.dt.year.values],dims=[\"year\"])\n",
    "nino34_yr_panel.name = \"nino34\"\n",
    "nino34_yr_df = nino34_yr_panel.to_dataframe().reset_index()\n",
    "\n",
    "panel = pd.merge(panel,E_yr_df,on=[\"year\"],how=\"left\")\n",
    "panel = pd.merge(panel,C_yr_df,on=[\"year\"],how=\"left\")\n",
    "panel = pd.merge(panel,nino3_yr_df,on=[\"year\"],how=\"left\")\n",
    "panel = pd.merge(panel,nino34_yr_df,on=[\"year\"],how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add teleconnections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_tc = 1960\n",
    "y2_tc = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc_ds = xr.open_dataset(loc_teleconnections+\"ENSO_observed_teleconnections_DJF_\"+str(y1_tc)+\"-\"+str(y2_tc)+\".nc\")\n",
    "\n",
    "for ind in [\"e\",\"c\"]:\n",
    "    \n",
    "    # precipitation with sign preserved, not absolute value\n",
    "    p_corr2 = tc_ds.data_vars[\"p_corr2_\"+ind]\n",
    "    p_corr2.name = \"p_corr2_\"+ind\n",
    "    panel = pd.merge(panel,p_corr2.to_dataframe().reset_index(),\n",
    "                     on=[\"iso\"],how=\"left\")\n",
    "\n",
    "    # combined correlation\n",
    "    tp_corr = tc_ds.data_vars[\"combined_corr_\"+ind]\n",
    "    tp_corr.name = \"t_p_corr_\"+ind\n",
    "    tp_corr_df = tp_corr.to_dataframe().reset_index()\n",
    "    panel = pd.merge(panel,tp_corr_df,on=[\"iso\"],how=\"left\")\n",
    "    \n",
    "    # combined regression coefficient\n",
    "    tp_reg = tc_ds.data_vars[\"combined_reg_\"+ind]\n",
    "    tp_reg.name = \"t_p_reg_\"+ind\n",
    "    tp_reg_df = tp_reg.to_dataframe().reset_index()\n",
    "    panel = pd.merge(panel,tp_reg_df,on=[\"iso\"],how=\"left\")\n",
    "    \n",
    "    # combined correlation coefficient running\n",
    "    tp_corr_running = tc_ds.data_vars[\"combined_corr_\"+ind+\"_running\"]\n",
    "    tp_corr_running.name = \"t_p_corr_running_\"+ind\n",
    "    tp_corr_running_df = tp_corr_running.to_dataframe().reset_index()\n",
    "    panel = pd.merge(panel,tp_corr_running_df,on=[\"iso\"],how=\"left\")\n",
    "    \n",
    "    # temp running correlation coefficient\n",
    "    t_corr_running = tc_ds.data_vars[\"t_corr_running_\"+ind]\n",
    "    t_corr_running.name = \"t_corr_running_\"+ind\n",
    "    t_corr_running_df = t_corr_running.to_dataframe().reset_index()\n",
    "    panel = pd.merge(panel,t_corr_running_df,on=[\"iso\"],how=\"left\")\n",
    "    \n",
    "    # precip running correlation coefficient\n",
    "    p_corr_running = tc_ds.data_vars[\"p_corr_running_\"+ind]\n",
    "    p_corr_running.name = \"p_corr_running_\"+ind\n",
    "    p_corr_running_df = p_corr_running.to_dataframe().reset_index()\n",
    "    panel = pd.merge(panel,p_corr_running_df,on=[\"iso\"],how=\"left\")\n",
    "    \n",
    "    # combined regression coefficient running\n",
    "    tp_reg_running = tc_ds.data_vars[\"combined_reg_\"+ind+\"_running\"]\n",
    "    tp_reg_running.name = \"t_p_reg_running_\"+ind\n",
    "    tp_reg_running_df = tp_reg_running.to_dataframe().reset_index()\n",
    "    panel = pd.merge(panel,tp_reg_running_df,on=[\"iso\"],how=\"left\")\n",
    "    \n",
    "    # cumulative running correlation coefficient\n",
    "    tp_corr_running_sum = tc_ds.data_vars[\"combined_corr_\"+ind+\"_sum\"]\n",
    "    tp_corr_running_sum.name = \"t_p_corr_sum_\"+ind\n",
    "    tp_corr_running_sum_df = tp_corr_running_sum.to_dataframe().reset_index()\n",
    "    panel = pd.merge(panel,tp_corr_running_sum_df,on=[\"iso\"],how=\"left\")\n",
    "    \n",
    "    # cumulative running reg coefficient\n",
    "    tp_reg_running_sum = tc_ds.data_vars[\"combined_reg_\"+ind+\"_sum\"]\n",
    "    tp_reg_running_sum.name = \"t_p_reg_sum_\"+ind\n",
    "    tp_reg_running_sum_df = tp_reg_running_sum.to_dataframe().reset_index()\n",
    "    panel = pd.merge(panel,tp_reg_running_sum_df,on=[\"iso\"],how=\"left\")\n",
    "    \n",
    "    # temp cumulative running correlation coefficient\n",
    "    t_corr_running_sum = tc_ds.data_vars[\"t_corr_\"+ind+\"_sum\"]\n",
    "    t_corr_running_sum.name = \"t_corr_sum_\"+ind\n",
    "    t_corr_running_sum_df = t_corr_running_sum.to_dataframe().reset_index()\n",
    "    panel = pd.merge(panel,t_corr_running_sum_df,on=[\"iso\"],how=\"left\")\n",
    "    \n",
    "    # precip cumulative running correlation coefficient\n",
    "    p_corr_running_sum = tc_ds.data_vars[\"p_corr_\"+ind+\"_sum\"]\n",
    "    p_corr_running_sum.name = \"p_corr_sum_\"+ind\n",
    "    p_corr_running_sum_df = p_corr_running_sum.to_dataframe().reset_index()\n",
    "    panel = pd.merge(panel,p_corr_running_sum_df,on=[\"iso\"],how=\"left\")\n",
    "    \n",
    "    # only statistically significant sum\n",
    "    tp_corr_sig_sum = tc_ds.data_vars[\"combined_corr_\"+ind+\"_sum_sig\"]\n",
    "    tp_corr_sig_sum.name = \"t_p_corr_sum_sig_\"+ind\n",
    "    tp_corr_sig_sum_df = tp_corr_sig_sum.to_dataframe().reset_index()\n",
    "    panel = pd.merge(panel,tp_corr_sig_sum_df,on=[\"iso\"],how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add temp and precip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_temp_panel = xr.DataArray(country_temp.values,\n",
    "                                coords=[country_temp.iso,\n",
    "                                        country_temp.time.dt.year.values],\n",
    "                                 dims=[\"iso\",\"year\"])\n",
    "country_precip_panel = xr.DataArray(country_precip.values,\n",
    "                                coords=[country_precip.iso,\n",
    "                                        country_precip.time.dt.year.values],\n",
    "                                 dims=[\"iso\",\"year\"])\n",
    "country_temp_panel.name = \"t\"\n",
    "country_precip_panel.name = \"p\"\n",
    "country_temp_df = country_temp_panel.to_dataframe().reset_index()\n",
    "country_precip_df = country_precip_panel.to_dataframe().reset_index()\n",
    "\n",
    "panel = pd.merge(panel,country_temp_df,on=[\"iso\",\"year\"],how=\"left\")\n",
    "panel = pd.merge(panel,country_precip_df,on=[\"iso\",\"year\"],how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add GPC from World Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "panel = pd.merge(panel,wdi_panel_long.rename(columns={\"gdppc\":\"gpc\"}),on=[\"iso\",\"year\"],how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in Penn World Tables and add to panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwt_in = pd.read_csv(loc_pwt+\"pwt10-0.csv\",engine=\"python\")\n",
    "pwt_iso = pwt_in.countrycode.values\n",
    "pwt_yr = pwt_in.year.values\n",
    "pwt_in[\"population\"] = pwt_in[\"pop\"]*1e6 # originally in millions\n",
    "pwt_in[\"gpc\"] = (pwt_in[\"rgdpna\"]*1e6)/pwt_in[\"population\"]\n",
    "pwt_in[\"gpc_ppp\"] = (pwt_in[\"rgdpo\"]*1e6)/pwt_in[\"population\"]\n",
    "# gdp = rgdpna\n",
    "# pop = pop\n",
    "# human capital = hc \n",
    "# capital stock = rkna\n",
    "\n",
    "# real consumption in millions = ccon\n",
    "# real domestic absorption in millions = cda\n",
    "\n",
    "# more info on PWT (specifically the capital data):\n",
    "# https://www.rug.nl/ggdc/docs/pwt100-user-guide-to-data-files.pdf\n",
    "# https://www.rug.nl/ggdc/docs/pwt91_whatsnew.pdf\n",
    "# https://www.rug.nl/ggdc/docs/pwt91_capitalservices_ipmrevision.pdf\n",
    "# https://www.rug.nl/ggdc/docs/pwt91_user_guide_to_data_files.pdf\n",
    "# also ag income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwt_for_panel = pwt_in.loc[:,[\"year\",\"countrycode\",\"population\",\"gpc\",\"rgdpna\",\"rkna\",\"rtfpna\",\n",
    "                             \"hc\",\"labsh\",\"delta\",\"ctfp\",\"emp\",\"rnna\",\"gpc_ppp\"]]\n",
    "pwt_for_panel = pwt_for_panel.rename(columns={\"countrycode\":\"iso\",\"population\":\"pop_pwt\",\n",
    "                                             \"gpc\":\"gpc_pwt\",\"rgdpna\":\"gdp_pwt\",\n",
    "                                             \"rkna\":\"capital\",\"rtfpna\":\"tfp\"})\n",
    "pwt_for_panel[\"gdp_pwt\"] = pwt_for_panel[\"gdp_pwt\"]*1e6\n",
    "pwt_for_panel[\"cspercap\"] = (pwt_for_panel[\"rnna\"]*1e6)/pwt_for_panel[\"pop_pwt\"]\n",
    "#pwt_for_panel[\"capitalstock\"] = pwt_for_panel[\"capitalstock\"]*1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "panel = pd.merge(panel,pwt_for_panel,on=[\"iso\",\"year\"],how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixed effects (dummy variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = panel.loc[:,\"iso\"].values\n",
    "countries_sorted = list(sorted(set(countries)))\n",
    "years = panel.loc[:,\"year\"].values.astype(int)\n",
    "\n",
    "zrs_ctry = np.zeros(len(years))\n",
    "for i in np.arange(0,len(countries_sorted),1):\n",
    "    zrs_lin = np.zeros(len(years))\n",
    "    zrs_quad = np.zeros(len(years))\n",
    "    indices = countries == countries_sorted[i]\n",
    "    y_lin = years[indices] - y1\n",
    "    y_quad = y_lin**2\n",
    "    zrs_lin[indices] = y_lin\n",
    "    zrs_quad[indices] = y_quad\n",
    "    \n",
    "    indices_num = indices.astype(int)\n",
    "    zrs_ctry[indices] = [i+1] * len(indices_num[indices_num == 1])\n",
    "    \n",
    "    panel.loc[:,\"yi_linear_\"+str(i)] = zrs_lin\n",
    "    panel.loc[:,\"yi_quadratic_\"+str(i)] = zrs_quad\n",
    "    \n",
    "panel.loc[:,\"countrynum\"] = zrs_ctry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "panel[\"countrynum\"] = panel[\"countrynum\"].values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "panel.loc[:,\"lngpc\"] = np.log(panel.loc[:,\"gpc\"])\n",
    "panel.loc[:,\"lngpc_pwt\"] = np.log(panel.loc[:,\"gpc_pwt\"])\n",
    "panel.loc[:,\"lncs\"] = np.log(panel.loc[:,\"capital\"])\n",
    "panel.loc[:,\"lntfp\"] = np.log(panel.loc[:,\"tfp\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Growth in various quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "growth = np.zeros(len(years))\n",
    "for i in np.arange(0,len(countries_sorted),1):\n",
    "    indices = countries == countries_sorted[i]\n",
    "    gpc_ctry = panel.loc[indices,\"lngpc\"].values\n",
    "    diff = np.diff(gpc_ctry)\n",
    "    diffnan = np.insert(diff,0,np.nan)\n",
    "    indices_num = indices.astype(int)\n",
    "    growth[indices] = diffnan\n",
    "    \n",
    "panel.loc[:,\"growth\"] = growth\n",
    "\n",
    "growth_pwt = np.zeros(len(years))\n",
    "for i in np.arange(0,len(countries_sorted),1):\n",
    "    indices = countries == countries_sorted[i]\n",
    "    gpc_pwt_ctry = panel.loc[indices,\"lngpc_pwt\"].values\n",
    "    diff = np.diff(gpc_pwt_ctry)\n",
    "    diffnan = np.insert(diff,0,np.nan)\n",
    "    indices_num = indices.astype(int)\n",
    "    growth_pwt[indices] = diffnan\n",
    "    \n",
    "panel.loc[:,\"growth_pwt\"] = growth_pwt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional fractional growth quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_growth(panel_var_name,final_name,panel):\n",
    "    countries = panel.loc[:,\"iso\"].values\n",
    "    countries_sorted = list(sorted(set(countries)))\n",
    "    years = panel.loc[:,\"year\"].values.astype(int)\n",
    "    \n",
    "    growth_vals = np.zeros(len(years))\n",
    "    for i in np.arange(0,len(countries_sorted),1):\n",
    "        indices = countries == countries_sorted[i]\n",
    "        ctry_vals = panel.loc[indices,panel_var_name].values\n",
    "        diff = np.diff(ctry_vals)\n",
    "        frac_diff = diff/ctry_vals[:-1]\n",
    "        frac_diff_nan = np.insert(frac_diff,0,np.nan)\n",
    "        growth_vals[indices] = frac_diff_nan\n",
    "    panel.loc[:,final_name] = growth_vals\n",
    "    return(panel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "panel = add_growth(\"gpc_pwt\",\"gr_pwt_frac\",panel)\n",
    "panel = add_growth(\"pop_pwt\",\"gr_pop_frac\",panel)\n",
    "panel = add_growth(\"capital\",\"gr_cs_frac\",panel)\n",
    "panel = add_growth(\"tfp\",\"gr_tfp_frac\",panel)\n",
    "panel = add_growth(\"cspercap\",\"gr_cspc_frac\",panel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lat and lon for spatial clustering if desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "panel[\"lat\"] = np.full(len(years),np.nan)\n",
    "panel[\"lon\"] = np.full(len(years),np.nan)\n",
    "for i in np.arange(0,len(years_repeat),1):\n",
    "    code = iso_repeat[i]\n",
    "    if code in shp.ISO3.values:\n",
    "        panel.loc[panel.iso.values==code,\"lat\"] = shp.loc[shp[\"ISO3\"].values==code,\"LAT\"].values[0]\n",
    "        panel.loc[panel.iso.values==code,\"lon\"] = shp.loc[shp[\"ISO3\"].values==code,\"LON\"].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add regions and year-region combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = pd.read_csv(loc_regions+\"WPP2019_Regions_Processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "panel[\"region\"] = np.full(len(years),np.nan)\n",
    "for i in np.arange(0,len(years_repeat),1):\n",
    "    code = iso_repeat[i]\n",
    "    if code in regions.ISO3.values:\n",
    "        reg = regions.loc[regions.ISO3.values==code,\"RegionCode\"].values[0]\n",
    "        panel.loc[(panel.year.values==years_repeat[i])&(panel.iso.values==code),\"region\"] = reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "panel[\"yr_reg\"] = panel.year.values*1000 + panel.region.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add world bank low-income/high-income classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_class = pd.read_csv(loc_income_class+\"incomeclasses.csv\",engine=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "panel[\"income_group\"] = np.full(len(years),np.nan)\n",
    "iso_uq = np.unique(panel.iso.values)\n",
    "for i in np.arange(0,len(iso_uq),1):\n",
    "    code = iso_uq[i]\n",
    "    if code in income_class.Code.values:\n",
    "        iso_class = income_class.loc[income_class.Code.values==code,\"Income group\"].values[0]\n",
    "        if iso_class in [\"Low income\",\"Lower middle income\"]:\n",
    "            panel.loc[(panel.iso.values==code),\"income_group\"] = np.repeat(\"low\",np.sum(panel.iso.values==code))\n",
    "        elif iso_class in [\"High income\",\"Upper middle income\"]:\n",
    "            panel.loc[(panel.iso.values==code),\"income_group\"] = np.repeat(\"high\",np.sum(panel.iso.values==code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "panel.to_csv(loc_out+\"ENSO_Growth_Panel_\"+str(y1)+\"-\"+str(y2)+\".csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python ccallahan",
   "language": "python",
   "name": "ccallahan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
