{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Country-mean monthly temp and precip metrics\n",
    "#### Christopher Callahan\n",
    "#### Christopher.W.Callahan.GR@dartmouth.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mechanics\n",
    "Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap, cm\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "from rasterio import features\n",
    "from affine import Affine\n",
    "import geopandas as gp\n",
    "import descartes\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.feature import ShapelyFeature\n",
    "from scipy import stats\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_shp = \"../Data/ProcessedCountryShapefile/\"\n",
    "loc_pop = \"../Data/GPW/\"\n",
    "loc_temp_best = \"\" #\"/path/to/berkeley/earth/\"\n",
    "loc_precip = \"\" #\"/path/to/gpcc/\"\n",
    "loc_out_temp = \"../Data/CountryTemp/\"\n",
    "loc_out_precip = \"../Data/CountryPrecip/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_from_latlon(lat, lon):\n",
    "    # Written by Alex Gottlieb\n",
    "    lat = np.asarray(lat)\n",
    "    lon = np.asarray(lon)\n",
    "    trans = Affine.translation(lon[0], lat[0])\n",
    "    scale = Affine.scale(lon[1] - lon[0], lat[1] - lat[0])\n",
    "    return trans * scale\n",
    "\n",
    "def rasterize_one(shape, latitude, longitude, fill=0, **kwargs):\n",
    "    \"\"\"Rasterize a shapefile geometry (polygon) onto the given\n",
    "    xarray coordinates. This only works for 1d latitude and longitude\n",
    "    arrays.\n",
    "    Written by Alex Gottlieb and modified by Chris Callahan\n",
    "    April 2020\n",
    "    \"\"\"\n",
    "    transform = transform_from_latlon(latitude, longitude)\n",
    "    out_shape = (len(latitude), len(longitude))\n",
    "    raster = features.rasterize(shape, out_shape=out_shape,\n",
    "                                fill=fill, transform=transform,\n",
    "                                dtype=float, **kwargs)\n",
    "    return xr.DataArray(raster, coords=[latitude,longitude], dims=[\"lat\",\"lon\"])\n",
    "\n",
    "def rasterize(shapes, coords, fill=np.nan, **kwargs):\n",
    "    \"\"\"Rasterize a list of (geometry, fill_value) tuples onto the given\n",
    "    xarray coordinates. This only works for 1d latitude and longitude\n",
    "    arrays.\n",
    "    \"\"\"\n",
    "    transform = transform_from_latlon(coords['lat'], coords['lon'])\n",
    "    out_shape = (len(coords['lat']), len(coords['lon']))\n",
    "    raster = features.rasterize(shapes, out_shape=out_shape,\n",
    "                                fill=fill, transform=transform,\n",
    "                                dtype=float, **kwargs)\n",
    "    return xr.DataArray(raster, coords=coords, dims=('lat', 'lon'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for flipping longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_lon_tll(da):\n",
    "    # flip 360 to 180 lon\n",
    "    # for time-lat-lon xarray dataarray\n",
    "\n",
    "    # get coords\n",
    "    lat_da = da.coords[\"lat\"]\n",
    "    lon_da = da.coords[\"lon\"]\n",
    "    time_da = da.coords[\"time\"]\n",
    "\n",
    "    # flip lon\n",
    "    lon_180 = (lon_da.values + 180) % 360 - 180\n",
    "\n",
    "    # new data array\n",
    "    da_180 = xr.DataArray(da.values,\n",
    "                          coords=[time_da,lat_da.values,lon_180],\n",
    "                          dims=[\"time\",\"lat\",\"lon\"])\n",
    "\n",
    "    # flip dataarray so it goes from -180 to 180 \n",
    "    # (instead of 0-180, -180-0)\n",
    "    lon_min_neg = np.amin(lon_180[lon_180<0])\n",
    "    lon_max_neg = np.amax(lon_180[lon_180<0])\n",
    "    lon_min_pos = np.amin(lon_180[lon_180>=0])\n",
    "    lon_max_pos = np.amax(lon_180[lon_180>=0])\n",
    "    da_180_flip = xr.concat([da_180.loc[:,:,lon_min_neg:lon_max_neg],\n",
    "                             da_180.loc[:,:,lon_min_pos:lon_max_pos]],\n",
    "                            dim=\"lon\")\n",
    "    return(da_180_flip)\n",
    "\n",
    "def flip_lon_ll(da):\n",
    "    # flip 360 to 180 lon\n",
    "    # for lat-lon xarray dataarray\n",
    "\n",
    "    # get coords\n",
    "    lat_da = da.coords[\"lat\"]\n",
    "    lon_da = da.coords[\"lon\"]\n",
    "\n",
    "    # flip lon\n",
    "    lon_180 = (lon_da.values + 180) % 360 - 180\n",
    "\n",
    "    # new data array\n",
    "    da_180 = xr.DataArray(da.values,\n",
    "                          coords=[lat_da,lon_180],\n",
    "                          dims=[\"lat\",\"lon\"])\n",
    "\n",
    "    # flip dataarray so it goes from -180 to 180 \n",
    "    # (instead of 0-180, -180-0)\n",
    "    lon_min_neg = np.amin(lon_180[lon_180<0])\n",
    "    lon_max_neg = np.amax(lon_180[lon_180<0])\n",
    "    lon_min_pos = np.amin(lon_180[lon_180>=0])\n",
    "    lon_max_pos = np.amax(lon_180[lon_180>=0])\n",
    "    da_180_flip = xr.concat([da_180.loc[:,lon_min_neg:lon_max_neg],\n",
    "                             da_180.loc[:,lon_min_pos:lon_max_pos]],\n",
    "                            dim=\"lon\")\n",
    "    return(da_180_flip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Population data -- may need multiple resolutions for different-resolution T and P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# half degree\n",
    "pop_halfdegree = (xr.open_dataset(loc_pop+\"30ArcMinute/gpw_v4_une_atotpopbt_cntm_30_min_lonflip.nc\").data_vars[\"population\"])[0,::-1,:]\n",
    "pop_flip_halfdegree = flip_lon_ll(pop_halfdegree.rename({\"latitude\":\"lat\",\"longitude\":\"lon\"}))\n",
    "lat_min_halfdegree = np.amin(pop_flip_halfdegree.lat.values)\n",
    "lat_max_halfdegree = np.amax(pop_flip_halfdegree.lat.values)\n",
    "\n",
    "# one degree\n",
    "pop_onedegree = (xr.open_dataset(loc_pop+\"1Degree/gpw_v4_population_count_1degree_lonflip.nc\").data_vars[\"population\"])[0,::-1,:]\n",
    "pop_flip_onedegree = flip_lon_ll(pop_onedegree.rename({\"latitude\":\"lat\",\"longitude\":\"lon\"}))\n",
    "lat_min_onedegree = np.amin(pop_flip_onedegree.lat.values)\n",
    "lat_max_onedegree = np.amax(pop_flip_onedegree.lat.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp = gp.read_file(loc_shp)\n",
    "iso_shp = shp.ISO3.values\n",
    "isonums = {i: k for i, k in enumerate(shp.ISO3)}\n",
    "isonums_rev = {k: i for i, k in enumerate(shp.ISO3)}\n",
    "shapes = [(shape, n) for n, shape in enumerate(shp.geometry)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_temp = 1900\n",
    "y2_temp = 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_best = 1850\n",
    "y2_best = 2022\n",
    "tmean_best = xr.open_dataset(loc_temp_best+\"BerkeleyEarth_Land_and_Ocean_LatLong1.nc\").rename({\"latitude\":\"lat\",\"longitude\":\"lon\"})\n",
    "tmean_anom = tmean_best.temperature\n",
    "tmean_clm = tmean_best.climatology\n",
    "lsm1 = tmean_best.land_mask\n",
    "lsm = lsm1.where(lsm1==1,np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tmean_anom = xr.open_dataset(loc_temp_best+\"be_avg_temp_land_ocean.nc\").temperature.rename({\"latitude\":\"lat\",\"longitude\":\"lon\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "tmean_time_new = pd.date_range(start=str(y1_temp)+\"-01-01\",end=str(y2_temp)+\"-12-31\",freq=\"MS\")\n",
    "tmean_time_round = np.floor(tmean_anom.time.values)\n",
    "tmean_anom_yrs = tmean_anom[(tmean_time_round>=y1_temp)&(tmean_time_round<(y2_temp+1))]\n",
    "tmean_anom_yrs.coords[\"time\"] = tmean_time_new\n",
    "\n",
    "tmean_be = xr.DataArray(np.full(tmean_anom_yrs.shape,np.nan),\n",
    "                     coords=[tmean_time_new,tmean_anom_yrs.coords[\"lat\"],tmean_anom_yrs.coords[\"lon\"]],\n",
    "                     dims=[\"time\",\"lat\",\"lon\"])\n",
    "for mm in np.arange(0,12,1):\n",
    "    print(mm)\n",
    "    indices = tmean_time_new.month==(mm+1)\n",
    "    tmean_be[indices,:,:] = tmean_anom_yrs[indices,:,:] + tmean_clm[mm,:,:]\n",
    "    \n",
    "tmean_best_foravg = tmean_be.loc[:,lat_min_onedegree:lat_max_onedegree,:] #*lsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmean = tmean_best_foravg*1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in GPCP precip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "precip = xr.open_dataset(loc_precip+\"precip.mon.total.v2020.nc\").precip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y1_temp = 1979\n",
    "#y2_temp = 2018\n",
    "y1_precip = 1900\n",
    "y2_precip = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_yrs = precip[:,::-1,:].loc[str(y1_precip)+\"-01-01\":str(y2_precip)+\"-12-31\",lat_min_halfdegree:lat_max_halfdegree,:]\n",
    "precip_flip = flip_lon_tll(precip_yrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xr_country_average(data,y1,y2,freq,shapes,iso_list,isonums_dict,weight=False,weightdata=None):\n",
    "    time = pd.date_range(start=str(y1)+\"-01-01\",end=str(y2)+\"-12-31\",freq=freq)\n",
    "    country_array = xr.DataArray(np.full((len(iso_list),len(time)),np.nan),\n",
    "                                 coords=[iso_list,time],\n",
    "                                 dims=[\"iso\",\"time\"])\n",
    "    \n",
    "    isoraster = rasterize(shapes,data.drop(\"time\").coords)\n",
    "    data.coords[\"country\"] = isoraster\n",
    "    if weight:\n",
    "        weightdata.coords[\"country\"] = isoraster\n",
    "        countrymean = ((data * weightdata).groupby(\"country\").sum())/(weightdata.groupby(\"country\").sum())\n",
    "    else:\n",
    "        countrymean = data.groupby(\"country\").mean()\n",
    "    \n",
    "    isocoord = np.array([isonums_dict[n] for n in countrymean.coords[\"country\"].values])\n",
    "    country_array.loc[isocoord,:] = countrymean.transpose(\"country\",\"time\").values\n",
    "    return(country_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmean_country = xr_country_average(tmean,y1_temp,y2_temp,\"MS\",\n",
    "                                  shapes,iso_shp,isonums,True,pop_flip_onedegree)\n",
    "#tmean_country = tmean_country - 273.15\n",
    "\n",
    "precip_country = xr_country_average(precip_flip,y1_precip,y2_precip,\"MS\",\n",
    "                                  shapes,iso_shp,isonums,True,pop_flip_halfdegree) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dartfs-hpc/rc/home/y/f003k8y/.conda/envs/ccallahan/lib/python3.7/site-packages/xarray/core/nanops.py:142: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis=axis, dtype=dtype)\n",
      "/dartfs-hpc/rc/home/y/f003k8y/.conda/envs/ccallahan/lib/python3.7/site-packages/xarray/core/nanops.py:142: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis=axis, dtype=dtype)\n"
     ]
    }
   ],
   "source": [
    "tmean_country_anom = (tmean_country.groupby(\"time.month\") - (tmean_country.groupby(\"time.month\").mean(dim=\"time\")))\n",
    "tmean_country_std = tmean_country_anom.groupby(\"time.month\")/tmean_country.groupby(\"time.month\").std(dim=\"time\")\n",
    "\n",
    "precip_country_anom = (precip_country.groupby(\"time.month\") - (precip_country.groupby(\"time.month\").mean(dim=\"time\")))\n",
    "precip_country_std = precip_country_anom.groupby(\"time.month\")/precip_country.groupby(\"time.month\").std(dim=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/CountryTemp/BerkeleyEarth_country_temp_monthly_1900-2019.nc\n",
      "../Data/CountryTemp/BerkeleyEarth_country_temp_monthly_std_1900-2019.nc\n"
     ]
    }
   ],
   "source": [
    "tmean_country.name = \"temp\"\n",
    "tmean_country.attrs[\"creation_date\"] = str(datetime.datetime.now())\n",
    "tmean_country.attrs[\"created_by\"] = \"Christopher Callahan, Christopher.W.Callahan.GR@dartmouth.edu\"\n",
    "tmean_country.attrs[\"variable_description\"] = \"Monthly average temperature at the country level, BEST/20CR/UDel\"\n",
    "tmean_country.attrs[\"created_from\"] = os.getcwd()+\"/Process_Country_TempPrecip.ipynb\"\n",
    "tmean_country.attrs[\"coords\"] = \"iso x time\"\n",
    "tmean_country.attrs[\"units\"] = \"Degrees C\"\n",
    "\n",
    "fname_out = loc_out_temp+\"BerkeleyEarth_country_temp_monthly_\"+str(y1_temp)+\"-\"+str(y2_temp)+\".nc\"\n",
    "tmean_country.to_netcdf(fname_out,mode=\"w\")\n",
    "print(fname_out)\n",
    "\n",
    "tmean_country_std.name = \"temp\"\n",
    "tmean_country_std.attrs[\"creation_date\"] = str(datetime.datetime.now())\n",
    "tmean_country_std.attrs[\"created_by\"] = \"Christopher Callahan, Christopher.W.Callahan.GR@dartmouth.edu\"\n",
    "tmean_country_std.attrs[\"variable_description\"] = \"Standardized monthly average temperature at the country level, BEST/20CR/UDe;\"\n",
    "tmean_country_std.attrs[\"created_from\"] = os.getcwd()+\"/Process_Country_TempPrecip.ipynb\"\n",
    "tmean_country_std.attrs[\"coords\"] = \"iso x time\"\n",
    "tmean_country_std.attrs[\"units\"] = \"standard deviations\"\n",
    "\n",
    "fname_out = loc_out_temp+\"BerkeleyEarth_country_temp_monthly_std_\"+str(y1_temp)+\"-\"+str(y2_temp)+\".nc\"\n",
    "tmean_country_std.to_netcdf(fname_out,mode=\"w\")\n",
    "print(fname_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/CountryPrecip/GPCC_country_precip_monthly_1900-2019.nc\n",
      "../Data/CountryPrecip/GPCC_country_precip_monthly_std_1900-2019.nc\n"
     ]
    }
   ],
   "source": [
    "precip_country.name = \"precip\"\n",
    "precip_country.attrs[\"creation_date\"] = str(datetime.datetime.now())\n",
    "precip_country.attrs[\"created_by\"] = \"Christopher Callahan, Christopher.W.Callahan.GR@dartmouth.edu\"\n",
    "precip_country.attrs[\"variable_description\"] = \"Monthly total precip, averaged over country\"\n",
    "precip_country.attrs[\"created_from\"] = os.getcwd()+\"/Process_Country_TempPrecip.ipynb\"\n",
    "precip_country.attrs[\"coords\"] = \"iso x time\"\n",
    "precip_country.attrs[\"units\"] = \"millimeters\"\n",
    "\n",
    "fname_out = loc_out_precip+\"GPCC_country_precip_monthly_\"+str(y1_precip)+\"-\"+str(y2_precip)+\".nc\"\n",
    "precip_country.to_netcdf(fname_out,mode=\"w\")\n",
    "print(fname_out)\n",
    "\n",
    "precip_country_std.name = \"precip\"\n",
    "precip_country_std.attrs[\"creation_date\"] = str(datetime.datetime.now())\n",
    "precip_country_std.attrs[\"created_by\"] = \"Christopher Callahan, Christopher.W.Callahan.GR@dartmouth.edu\"\n",
    "precip_country_std.attrs[\"variable_description\"] = \"Standardized monthly total precip, averaged over country\"\n",
    "precip_country_std.attrs[\"created_from\"] = os.getcwd()+\"/Process_Country_TempPrecip.ipynb\"\n",
    "precip_country_std.attrs[\"coords\"] = \"iso x time\"\n",
    "precip_country_std.attrs[\"units\"] = \"standard deviations\"\n",
    "\n",
    "fname_out = loc_out_precip+\"GPCC_country_precip_monthly_std_\"+str(y1_precip)+\"-\"+str(y2_precip)+\".nc\"\n",
    "precip_country_std.to_netcdf(fname_out,mode=\"w\")\n",
    "print(fname_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python ccallahan",
   "language": "python",
   "name": "ccallahan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
